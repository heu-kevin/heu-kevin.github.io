<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Multi-Arm Bandits问题</title>
    <url>/2021/04/10/Multi-Arm-Bandits%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>Multi-Arm Bandits问题是从赌场中的多臂老虎机中提取的数学问题，可以使用强化学习来解决。本文参考于<a href="https://blog.csdn.net/coffee_cream/article/details/58034628">博客链接</a></p>
<span id="more"></span>
<h1 id="问题介绍"><a href="#问题介绍" class="headerlink" title="问题介绍"></a>问题介绍</h1><p><img src="mab.png"></p>
<p>一个赌徒，去赌场摇老虎机，发现老虎机共有$M$个摇杆，摇动任意一个摇杆都有一定概率获得金币，但是每个摇杆出金币的概率不一样，且对于赌徒来说是未知的，那么在每次选择摇动哪个摇杆时，如何进行决策来最大化收益呢？</p>
<p>显然，在这个问题下，每一回合一共有$M$个action可以选择（对应摇动$M$个摇杆之一），每个action都有一个服从某种概率分布的reward。将第$t$次执行的动作action记为$A_t$，其对应的奖励reward记为$R_t$，奖励在该摇杆的分布中的真实期望值记为$q_<em>(a)$，因此有$q_</em>(a)=E[R_t|A_t=a]$</p>
<p>如果我们知道所有摇杆的$q_*(a)$，那么问题就解决了，但是显然没有这么简单，我们无从得知真实的奖励期望值。</p>
<h1 id="强化学习下的解决方法"><a href="#强化学习下的解决方法" class="headerlink" title="强化学习下的解决方法"></a>强化学习下的解决方法</h1><p>使用强化学习来构造$Q_<em>(a)\approx q_</em>(a)$，而最简单的方式就是令$Q_*(a)$等于动作$a$的历史奖励的平均值，即：</p>
<script type="math/tex; mode=display">Q_*(a)\dot{=}\frac{sum\, of\, rewards\, when\, a\, taken\, prior\, to\, t}{number\, of\, times\, a\, taken\, prior\, to\, t}=\frac{\sum _{i=1}^{t-1}R_i\cdot l_{A_i=a}}{\sum _{i=1}^{t-1}l_{A_i=a}}</script><p>其中，当$A_i=a$为真时，$l_{A_i=a}=1$，否则等于0</p>
<p>那么，每次都选择动作$a=\underset {a}{argmax}\, Q_*(a)$就可以了。</p>
<h2 id="存在的问题（1）"><a href="#存在的问题（1）" class="headerlink" title="存在的问题（1）"></a>存在的问题（1）</h2><p>然而，简单按照上面的方法执行下去还存在着一个巨大的问题，就是只利用了当前已知的信息，没有开发未知的操作，这样就会出问题。举个例子，如果赌徒在第一次进行摇杆操作时随机选择了中奖概率为50%的摇杆$arm_x$，并且获得了奖励，那么$Q_<em>(a_x)=1$，而另一个摇杆$arm_y$的中奖概率为90%，但是赌徒第二次选择摇动$arm_y$时恰好没有中奖，于是$Q_</em>(a_y)=0$，这样根据已有知识，赌徒就会在接下来的回合一直选择摇动摇杆$arm_x$。这样显然是不合理的，因此我们需要适当地开发未知的领域，要给那些$Q_*(a)$较低的摇杆一些机会证明自己。</p>
<p>所以，赌徒在进行动作决策时，应该有两种操作：</p>
<ul>
<li>exploit操作：根据已有的知识进行动作的最优选择，可以最大化当前步的奖励。</li>
<li>explore操作：不选择当前最优的动作，去探索其他动作，可以提高对行为准确值的估计准确度。</li>
</ul>
<h2 id="epsilon-greedy方法"><a href="#epsilon-greedy方法" class="headerlink" title="$\epsilon-$greedy方法"></a>$\epsilon-$greedy方法</h2><p>引入一个较小的常量$\epsilon$，并且有$0&lt;\epsilon &lt;1$，在每次进行决策时，以$1-\epsilon$的概率选择$a=\underset {a}{argmax}\, Q_*(a)$，以$\epsilon$的概率从所有摇杆中以相等的概率随机选择一个摇杆。这种方法称为$\epsilon-$greedy方法，可以缓解前面存在的问题。</p>
<p>p.s.也可以将所有动作的初始估计期望值$Q_*(a)$设置为一个较大的值，而不是0，这样鼓励赌徒去进行explore操作。</p>
<h2 id="存在的问题（2）"><a href="#存在的问题（2）" class="headerlink" title="存在的问题（2）"></a>存在的问题（2）</h2><p>但是前面的方法还存在一个问题。随着回合数的增多，要将所有回合的历史记录全部记录下来并平均，开销很大。</p>
<h2 id="增量式实现"><a href="#增量式实现" class="headerlink" title="增量式实现"></a>增量式实现</h2><p>在$\epsilon-$greedy方法的基础上，可以进行增量式实现来解决问题（2）。</p>
<p>为了简化符号，这里只关注一个动作action，将第$i$次执行该动作时获得的奖励记为$R_i$，$Q_n$代表该动作执行了$n$次之后的期望估计值。那么有：</p>
<script type="math/tex; mode=display">\begin{align} 

Q_{n+1}&\dot{=}\frac{1}{n}\sum_{i=1}^{n}R_i \\

&=\frac{1}{n}(R_n+\sum_{i=1}^{n-1}R_i)\\

&=\frac{1}{n}(R_n+(n-1)\frac{1}{n-1} \sum_{i=1}^{n-1}R_i)\\

&=\frac{1}{n}(R_n+(n-1)Q_n)\\

&=\frac{1}{n}(R_n+nQ_n-Q_n)\\

&=Q_n+\frac{1}{n}[R_n-Q_n]

\end{align}</script><p>可以看到增量式实现是在旧的估计值上添加估计值与实际值的误差乘以$\frac{1}{n}$（随回合数变化，可以理解为step-size）来获得新的估计值。算法伪代码如下图：</p>
<p><img src="code.png"></p>
<h2 id="存在的问题（3）及其解决方案"><a href="#存在的问题（3）及其解决方案" class="headerlink" title="存在的问题（3）及其解决方案"></a>存在的问题（3）及其解决方案</h2><p>之前讨论的问题都是一个不变的环境，如果每个摇杆的中奖概率会随着时间发生改变呢？那么显然需要在进行增量式更新的时候不要令step-size随着时间的推移而越来越小（如$\frac{1}{n}$），最常用的方法是将其设为一个常数$\alpha\in(0,1]$，即：$Q_{n+1}\dot{=}Q_n+\alpha[R_n-Q_n]$</p>
<p>对该式进行分解得到：</p>
<p><img src="1.png"></p>
<p>又因为$(1-\alpha)^n+\sum_{i=a}^n\alpha (1-\alpha)^{n-i}=1$，因此可以将上式看作一种加权平均。由于$1-\alpha &lt;1$，因此$i$越大，赋予$R_i$的权重越大，也就是越新的奖励对估计值的影响越大。</p>
<h2 id="Upper-Confidence-Bound-Action-Selection"><a href="#Upper-Confidence-Bound-Action-Selection" class="headerlink" title="Upper-Confidence-Bound Action Selection"></a>Upper-Confidence-Bound Action Selection</h2><p>$\epsilon-$greedy被认为不是最优的explore方式，应该将每个action的评估值和不确定性均考虑在内，即下式：</p>
<p>$A_t\dot{=}\underset{a}{argmax}[Q_t(a)+c\sqrt{\frac{\log t}{N_t(a)}}]$</p>
<p>其中$\log$指的是自然对数，$N_t(a)$指的是动作$a$在回合$t$被执行的次数，常数$c&gt;0$代表的是赋予explore的权重。</p>
<p>参考文献：</p>
<p>[1] Reinforcement Learning: An Introduction, Richard S. Sutton and Andrew G. Barto</p>
<p>[2] UCL Course on RL</p>
<p>[3] <a href="https://blog.csdn.net/coffee_cream/article/details/58034628">https://blog.csdn.net/coffee_cream/article/details/58034628</a></p>
]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title>hello-blog</title>
    <url>/2021/03/21/hello-blog/</url>
    <content><![CDATA[<p>打今儿起，我也终于有自己的博客啦！</p>
]]></content>
      <categories>
        <category>啥也不是</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2021/03/21/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>个性化联邦学习：Personalized Federated Learning</title>
    <url>/2021/03/24/%E4%B8%AA%E6%80%A7%E5%8C%96%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9APersonalized-Federated-Learning/</url>
    <content><![CDATA[<p>今日调研了Alireza Fallah等人提出的个性化联邦学习，<a href="https://arxiv.org/abs/2002.07948">论文链接</a></p>
<span id="more"></span>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>在联邦学习场景中，存在$n$个参与方和一个服务器，其中每个参与方都只能访问自己本地的数据样本，利用本地数据样本训练本地模型，再将本地模型参数上传至服务器，服务器收到所有进行本地训练的参与方的本地模型参数后，对其进行聚合（往往是加权平均）获得全局模型参数，再将其广播给所有的参与方，进行下一轮训练。将$f_i:R^d\rightarrow R$作为参与方$i$的损失函数，那么联邦学习的目标就是：</p>
<p>​                                                                              ${\underset {w\in R^d}{min}}f(w):=\frac{1}{n}\sum_{i=1}^nf_i(w)$           (1)</p>
<p>对于监督学习，$f_i$可以代表参与方$i$的本地数据分布上的期望损失：</p>
<p>​                                                                              $f_i(w):=E_{(x,y)\sim p_i}[l_i(w;x,y)]$        (2)</p>
<p>其中$l_i(w;x,y)$代表模型$w$在预测标签为$y$的样本$x$时造成的损失，$p_i$是用户$i$的数据分布。在数据异构性强的设定下不同参与方的本地数据的分布是互不相同的。那么$f_i(w)$同样可以写作$f_i(w)=\sum_{(x,y)\in S_i}p_i(x,y)l_i(w;x,y)$，其中$S_i$代表参与方$i$的本地数据集，$p_i(x,y)$代表该样本在参与方$i$的本地数据集被采样的概率。</p>
<p>这样子最后获得的全局模型并不能适用于每个用户，特别是在用户的底层数据分布不相同的异构设置中，通过最小化平均损失获得的全局模型一旦应用到每个用户的本地数据集上，可能会执行得很糟糕。换句话说，式（1）给出的解决方案并不是针对每个用户的个性化，不能完全实现特定于用户的模型。</p>
<p>故而本文作者提出了个性化联邦学习，其目标是找到一个所有参与方共享的初始点，每个参与方依据其自身的损失函数更新这个初始点，执行比较少的梯度更新步骤就可以表现良好。这样，虽然初始模型在所有参与方中一致，但每个参与方实现的最终模型根据其本地数据的不同而不同。作者研究了FedAvg算法的变体——Per-FedAvg，用于解决个性化联邦学习问题。</p>
<h2 id="通过MAML进行个性化联邦学习"><a href="#通过MAML进行个性化联邦学习" class="headerlink" title="通过MAML进行个性化联邦学习"></a>通过MAML进行个性化联邦学习</h2><p>首先回顾MAML。与传统的监督学习设置不同，在MAML中，给定一组从基础分布中抽取的任务，目标不是找到一个在预期的所有任务上都表现良好的模型，而是找到一个初始化模型，它基于新的任务在经过较少的训练更新步骤之后，在该任务上表现良好。特别地，作者假设联邦学习中每个参与方都取这个初始点，并根据自身的损失函数更新一次模型，那么式（1）中的问题就变成了：</p>
<p>​                                                                      ${\underset {w\in R^d}{min}}F(w):=\frac{1}{n}\sum_{i=1}^nf_i(w-\alpha \nabla f_i(w))$       (3)</p>
<p>这样不仅保持了联邦学习的优点，也捕获了不同参与方之间的区别。这样式（3）求得的解决方案就可以作为初始模型分发给各个参与方，各个参与方在此基础上依据本地数据进行较少的训练更新步骤就可以获取一个适合自己的数据集的模型。</p>
<h2 id="个性化联邦学习算法：Per-Fedavg"><a href="#个性化联邦学习算法：Per-Fedavg" class="headerlink" title="个性化联邦学习算法：Per-Fedavg"></a>个性化联邦学习算法：Per-Fedavg</h2><p>式（3）中的$F$可以写作元函数$F_1,F_2,…,F_n$的平均，其中元函数$F_i$代表参与方$i$的元函数：</p>
<p>​                                                                  $F_i(w):=f_i(w-\alpha \nabla f_i(w))$              (4)</p>
<p>类似于FedAvg，第一步是各个参与方计算本地元函数的梯度：</p>
<p>​                                                                $\nabla F_i(w)=(I-\alpha \nabla ^2f_i(w))\nabla f_i(w-\alpha \nabla f_i(w))$        （5）</p>
<p>但是每一轮都计算$\nabla f_i(w)$代价很高，这里取一批关于分布$p_i$的数据$D^i$，得到一个无偏估计：</p>
<p>​                                                                $\widetilde \nabla f_i(w,D^i):=\frac{1}{|D^i|}\sum_{(x,y)\in D^i}\nabla l_i(w;x,y)$           （6）</p>
<p>同理，式（5）中的$\nabla ^2f_i(w)$可以用$\widetilde \nabla ^2f_i(w,D^i)$代替。</p>
<p>在Per-FedAvg的第k轮，类似于FedAVg，服务器将当前的全局模型发送给随机选择的一批参与方（也可以是全部参与方）$A_k$，每一个被选中的参与方都要在本地执行$\tau$个更新步骤，这样每个参与方都会生产一个本地模型参数序列$\{w^i_{k+1,t}\}^\tau _{t=0}$，其中$w_{k+1,0}^i=w_k$，并且满足$\tau \geq t\geq 1$  ：</p>
<p>​                                                                        $w_{k+1,t}^i=w_{k+1,t-1}^i-\beta \widetilde{\nabla}F_i(w_{k+1,t-1}^i)$        （7）</p>
<p>注意，所有局部迭代的$\widetilde{\nabla}F_i(w_{k+1,t-1}^i)$是使用互相独立的批次$D_t^i,D_t^{\prime i},D_t^{\prime \prime i}$计算的：</p>
<img src="/2021/03/24/%E4%B8%AA%E6%80%A7%E5%8C%96%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9APersonalized-Federated-Learning/1.png" class="">
<p>然后被选中的参与方将结果发送给服务器，服务器对收到的模型进行平均，获得全局模型$w_{k+1}=\frac{1}{|A_k|}\sum_{i\in A_k}w_{k+1,\tau}^i$。Per-FedAVg算法的伪代码如下图：</p>
<img src="/2021/03/24/%E4%B8%AA%E6%80%A7%E5%8C%96%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9APersonalized-Federated-Learning/2.png" class="">
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>实验部分就不再赘述了，具体细节见论文原文。这里贴上实验结果。</p>
<img src="/2021/03/24/%E4%B8%AA%E6%80%A7%E5%8C%96%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9APersonalized-Federated-Learning/3.png" class="">
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>这篇论文的作者提出的个性化联邦学习很有想法，值得我们学习，毕竟联邦学习大多数时候各个参与方的本地数据分布就是差异性极大，个性化联邦学习专门迎合这个问题，并尝试解决它。</p>
]]></content>
      <categories>
        <category>联邦学习</category>
      </categories>
      <tags>
        <tag>联邦学习</tag>
        <tag>元学习</tag>
      </tags>
  </entry>
  <entry>
    <title>小小酥的每日学习小结（1）</title>
    <url>/2021/04/04/%E5%B0%8F%E5%B0%8F%E9%85%A5%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%BB%93%EF%BC%881%EF%BC%89/</url>
    <content><![CDATA[<p>小小酥备战事业单位考试的学习总结第一天。</p>
<span id="more"></span>
<h1 id="每日学习小结"><a href="#每日学习小结" class="headerlink" title="每日学习小结"></a>每日学习小结</h1><h2 id="1-党建"><a href="#1-党建" class="headerlink" title="1.党建"></a>1.党建</h2><ol>
<li><p>党的性质、指导思想、宗旨</p>
</li>
<li><p>党的纲领&amp;路线</p>
</li>
<li><p>党的思想、组织、制度、作风、反腐倡廉</p>
</li>
<li><p>党的纪律&amp;统一团结</p>
</li>
<li><p>党&amp;党员</p>
</li>
</ol>
<h2 id="2-毛思"><a href="#2-毛思" class="headerlink" title="2.毛思"></a>2.毛思</h2><p>1.毛思形成的5个历史条件</p>
<p>2.毛思的四个阶段</p>
<p>每个阶段包含时期、著作、标志</p>
<ul>
<li>萌芽 </li>
<li>形成</li>
<li>成熟</li>
<li>发展</li>
</ul>
<h2 id="3-邓论"><a href="#3-邓论" class="headerlink" title="3.邓论"></a>3.邓论</h2><ol>
<li><p>邓论形成的4个历史条件</p>
</li>
<li><p>邓论形成&amp;发展的4个过程</p>
</li>
</ol>
]]></content>
      <categories>
        <category>小小酥事业单位考试</category>
      </categories>
      <tags>
        <tag>小小酥</tag>
        <tag>每日总结</tag>
      </tags>
  </entry>
  <entry>
    <title>小小酥的每日学习小结（2）</title>
    <url>/2021/04/05/%E5%B0%8F%E5%B0%8F%E9%85%A5%E7%9A%84%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%BB%93%EF%BC%882%EF%BC%89/</url>
    <content><![CDATA[<p>今天是小小酥备战事业单位考试的第二天。</p>
<span id="more"></span>
<h1 id="每日学习小结"><a href="#每日学习小结" class="headerlink" title="每日学习小结"></a>每日学习小结</h1><h2 id="1-毛思（下）"><a href="#1-毛思（下）" class="headerlink" title="1.毛思（下）"></a>1.毛思（下）</h2><h3 id="1-毛思科学内涵（3点）"><a href="#1-毛思科学内涵（3点）" class="headerlink" title="1.毛思科学内涵（3点）"></a>1.毛思科学内涵（3点）</h3><h3 id="2-毛思主要内容"><a href="#2-毛思主要内容" class="headerlink" title="2.毛思主要内容"></a>2.毛思主要内容</h3><ul>
<li>新民主主义革命理论</li>
<li>社主革命&amp;建设理论</li>
<li>人民军队</li>
<li>政策&amp;策略</li>
<li>思想政治&amp;文化工作</li>
<li>党的建设</li>
</ul>
<h3 id="3-毛思活的灵魂"><a href="#3-毛思活的灵魂" class="headerlink" title="3.毛思活的灵魂"></a>3.毛思活的灵魂</h3><p>实事求是、群众路线、独立自主</p>
<h2 id="2-邓论-邓论的主要内容"><a href="#2-邓论-邓论的主要内容" class="headerlink" title="2.邓论-邓论的主要内容"></a>2.邓论-邓论的主要内容</h2><h3 id="1-邓论的精髓"><a href="#1-邓论的精髓" class="headerlink" title="1.邓论的精髓"></a>1.邓论的精髓</h3><p>解放思想、实事求是</p>
<h3 id="2-邓论的本质-（important）"><a href="#2-邓论的本质-（important）" class="headerlink" title="2.邓论的本质 （important）"></a>2.邓论的本质 （important）</h3><h4 id="1）本质的形成-（4个阶段）"><a href="#1）本质的形成-（4个阶段）" class="headerlink" title="1）本质的形成 （4个阶段）"></a>1）本质的形成 （4个阶段）</h4><ul>
<li>1980，提出“生产力…一切…的标准“</li>
<li>1986，发展生产&amp;共同致富</li>
<li>1992，正式提出</li>
<li>促进人的全面发展</li>
</ul>
<h4 id="2）本质的内容"><a href="#2）本质的内容" class="headerlink" title="2）本质的内容"></a>2）本质的内容</h4><p>解放&amp;发展生产力，消灭剥削&amp;两级分化，共同富裕</p>
<h3 id="3-邓论的路线-amp-纲领"><a href="#3-邓论的路线-amp-纲领" class="headerlink" title="3.邓论的路线&amp;纲领"></a>3.邓论的路线&amp;纲领</h3><h4 id="1）路线"><a href="#1）路线" class="headerlink" title="1）路线"></a>1）路线</h4><p>团结和领导人民</p>
<p>一个中心两个基本点</p>
<p>自立更生，艰苦创业</p>
<p>富强民主文明和谐美丽的社主现代化强国</p>
<h4 id="2）纲领"><a href="#2）纲领" class="headerlink" title="2）纲领"></a>2）纲领</h4><ul>
<li>政治</li>
<li>经济</li>
<li>文化</li>
</ul>
<h3 id="4-邓论的发展战略-（important）"><a href="#4-邓论的发展战略-（important）" class="headerlink" title="4.邓论的发展战略 （important）"></a>4.邓论的发展战略 （important）</h3><h4 id="1）三步走"><a href="#1）三步走" class="headerlink" title="1）三步走"></a>1）三步走</h4><ol>
<li>十三大</li>
<li>十五大</li>
<li>十七大</li>
<li>十九大</li>
</ol>
<h4 id="2）新型工业化、区域经济、城镇化"><a href="#2）新型工业化、区域经济、城镇化" class="headerlink" title="2）新型工业化、区域经济、城镇化"></a>2）新型工业化、区域经济、城镇化</h4><h4 id="1-新型工业化"><a href="#1-新型工业化" class="headerlink" title="1.新型工业化"></a>1.新型工业化</h4><p>坚持以信息带动工业化，工业化促进信息化</p>
<p>科技、经济、资源、环境、人力</p>
<h4 id="2-区域经济"><a href="#2-区域经济" class="headerlink" title="2.区域经济"></a>2.区域经济</h4><p>西部大开发（12个省，5个自治区）</p>
<h4 id="3）科教兴国-amp-可持续发展战略"><a href="#3）科教兴国-amp-可持续发展战略" class="headerlink" title="3）科教兴国&amp;可持续发展战略"></a>3）科教兴国&amp;可持续发展战略</h4><p>对邓“科学是第一生产力“的实践&amp;贯彻落实</p>
<p>优先教育、关键在人</p>
<p>创新能力：综合国力决定性因素</p>
<p>生产发展、生活富裕、生态良好</p>
<h4 id="4）乡村振兴战略（补充，十九大提出）"><a href="#4）乡村振兴战略（补充，十九大提出）" class="headerlink" title="4）乡村振兴战略（补充，十九大提出）"></a>4）乡村振兴战略（补充，十九大提出）</h4><p>三农问题（农业农村农民）</p>
<h2 id="3-邓论-改革"><a href="#3-邓论-改革" class="headerlink" title="3.邓论-改革"></a>3.邓论-改革</h2><h3 id="1-制度-（革命是制度）"><a href="#1-制度-（革命是制度）" class="headerlink" title="1.制度 （革命是制度）"></a>1.制度 （革命是制度）</h3><ol>
<li>根本制度：社会主义制度</li>
<li>经济 （2）</li>
<li>政治 （一根本，三基本）</li>
<li>文化（null)</li>
</ol>
<h3 id="2-体制-（改革是体制）"><a href="#2-体制-（改革是体制）" class="headerlink" title="2.体制 （改革是体制）"></a>2.体制 （改革是体制）</h3><ol>
<li>经济：市场经济</li>
<li>政治：发展社主，推进政治改革（重要性，目标，内容，原则），依法治国</li>
<li>文化：特点，作用，内容</li>
</ol>
]]></content>
      <categories>
        <category>小小酥事业单位考试</category>
      </categories>
      <tags>
        <tag>小小酥</tag>
        <tag>每日总结</tag>
      </tags>
  </entry>
  <entry>
    <title>小小酥的每日学习小结（3）</title>
    <url>/2021/04/06/%E5%B0%8F%E5%B0%8F%E9%85%A5%E7%9A%84%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%BB%93%EF%BC%883%EF%BC%89/</url>
    <content><![CDATA[<p>今天是小小酥备战事业单位考试的第三天。</p>
<span id="more"></span>
<h1 id="每日学习小结"><a href="#每日学习小结" class="headerlink" title="每日学习小结"></a>每日学习小结</h1><h2 id="一、邓论（完结）"><a href="#一、邓论（完结）" class="headerlink" title="一、邓论（完结）"></a>一、邓论（完结）</h2><h2 id="1-邓论-开放"><a href="#1-邓论-开放" class="headerlink" title="1.邓论-开放"></a>1.邓论-开放</h2><p>格局：全方位、多层次、宽领域（立体化，19大）</p>
<ol>
<li>中现代化建设的国际环境</li>
<li>对外开放是我国的基本国策</li>
<li>独立自主是我国的和平外交政策</li>
<li>外交战略变化过程</li>
</ol>
<h2 id="2-邓论-军队"><a href="#2-邓论-军队" class="headerlink" title="2.邓论-军队"></a>2.邓论-军队</h2><p>现代化、正规化、革命化（现正革）</p>
<p>战略方正：积极防御</p>
<p>历史课题：“打得赢、不变质”</p>
<h2 id="3-邓论-一国两制"><a href="#3-邓论-一国两制" class="headerlink" title="3.邓论-一国两制"></a>3.邓论-一国两制</h2><ol>
<li>一国两制的形成&amp;发展</li>
<li>一国两制的基本内容（4点）</li>
<li>一国两制的成功实践（3点）</li>
<li>解决台湾问题的原则（4点）</li>
</ol>
<h2 id="4-邓论-依靠-amp-领导"><a href="#4-邓论-依靠-amp-领导" class="headerlink" title="4.邓论-依靠&amp;领导"></a>4.邓论-依靠&amp;领导</h2><h3 id="1-人民群众是社主的依靠力量"><a href="#1-人民群众是社主的依靠力量" class="headerlink" title="1)人民群众是社主的依靠力量"></a>1)人民群众是社主的依靠力量</h3><p>工农知识分子、各族人民团结、爱国统一战线、人民军队</p>
<h3 id="2-共产党是社主的领导核心"><a href="#2-共产党是社主的领导核心" class="headerlink" title="2)共产党是社主的领导核心"></a>2)共产党是社主的领导核心</h3><p>领导方式：（3）</p>
<p>执政方式：（3）</p>
<h3 id="3-按“三个代表”加强-amp-改进党的建设"><a href="#3-按“三个代表”加强-amp-改进党的建设" class="headerlink" title="3)按“三个代表”加强&amp;改进党的建设"></a>3)按“三个代表”加强&amp;改进党的建设</h3><h2 id="5-邓论-历史地位-amp-指导意义"><a href="#5-邓论-历史地位-amp-指导意义" class="headerlink" title="5.邓论-历史地位&amp;指导意义"></a>5.邓论-历史地位&amp;指导意义</h2><h2 id="二、三个代表"><a href="#二、三个代表" class="headerlink" title="二、三个代表"></a>二、三个代表</h2><p>2000年，广东，首次提出</p>
<h3 id="1-形成条件"><a href="#1-形成条件" class="headerlink" title="1.形成条件"></a>1.形成条件</h3><ul>
<li>历史根据</li>
<li>时代背景</li>
<li>现实依据</li>
</ul>
<h3 id="2-形成过程"><a href="#2-形成过程" class="headerlink" title="2.形成过程"></a>2.形成过程</h3><h3 id="3-历史地位-amp-之道意义"><a href="#3-历史地位-amp-之道意义" class="headerlink" title="3.历史地位&amp;之道意义"></a>3.历史地位&amp;之道意义</h3><h2 id="三、科学发展观"><a href="#三、科学发展观" class="headerlink" title="三、科学发展观"></a>三、科学发展观</h2><p>2003年，江西，明确使用</p>
<p>十七大写入党章</p>
<p>十八大作为党的指导细想写入党章</p>
]]></content>
      <categories>
        <category>小小酥事业单位考试</category>
      </categories>
      <tags>
        <tag>小小酥</tag>
        <tag>每日总结</tag>
      </tags>
  </entry>
  <entry>
    <title>小小酥的每日学习小结（4）</title>
    <url>/2021/04/07/%E5%B0%8F%E5%B0%8F%E9%85%A5%E7%9A%84%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%BB%93%EF%BC%884%EF%BC%89/</url>
    <content><![CDATA[<p>今天是小小酥备战事业单位考试的第四天。</p>
<span id="more"></span>
<h1 id="每日学习小结"><a href="#每日学习小结" class="headerlink" title="每日学习小结"></a>每日学习小结</h1><p>政治完结，今天着重整理政治笔记&amp;刷了部分题</p>
<p>开始学习经济板块</p>
<h2 id="一、政治刷题进度"><a href="#一、政治刷题进度" class="headerlink" title="一、政治刷题进度"></a>一、政治刷题进度</h2><ul>
<li>党史&amp;党建，159/544</li>
<li>毛思，120/218</li>
<li>邓论（未开始）</li>
</ul>
<h2 id="二、经济基原"><a href="#二、经济基原" class="headerlink" title="二、经济基原"></a>二、经济基原</h2><h3 id="1-市场的含义"><a href="#1-市场的含义" class="headerlink" title="1.市场的含义"></a>1.市场的含义</h3><ul>
<li>场所</li>
<li>支付能力的需求</li>
<li>交换关系</li>
</ul>
<h3 id="2-市场的要素"><a href="#2-市场的要素" class="headerlink" title="2.市场的要素"></a>2.市场的要素</h3><ul>
<li>主体（人），3类</li>
<li>客体（商品），2类</li>
<li>行为，3种</li>
<li>秩序（是前提）</li>
</ul>
<h3 id="3-市场经济含"><a href="#3-市场经济含" class="headerlink" title="3.市场经济含"></a>3.市场经济含</h3><ul>
<li>根源</li>
<li>含义</li>
<li>发展过程 （3个）</li>
<li>阶段（2个）</li>
<li>与商品经济的关系</li>
</ul>
]]></content>
      <categories>
        <category>小小酥事业单位考试</category>
      </categories>
      <tags>
        <tag>小小酥</tag>
        <tag>每日总结</tag>
      </tags>
  </entry>
  <entry>
    <title>小小酥的每日学习小结（5）</title>
    <url>/2021/04/08/%E5%B0%8F%E5%B0%8F%E9%85%A5%E7%9A%84%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%BB%93%EF%BC%885%EF%BC%89/</url>
    <content><![CDATA[<p>今天是小小酥备战事业单位考试的第五天。</p>
<span id="more"></span>
<h1 id="每日学习小结"><a href="#每日学习小结" class="headerlink" title="每日学习小结"></a>每日学习小结</h1><h2 id="一、市场经济"><a href="#一、市场经济" class="headerlink" title="一、市场经济"></a>一、市场经济</h2><p>自然经济————&gt;商品经济————&gt;产品经济</p>
<p>（自给自足）——&gt;（交换）——&gt;（按需分配）</p>
<p>商品经济：市场经济（市场机制调控）&amp;计划经济（国家调控）</p>
<h3 id="2-市场经济基本特征"><a href="#2-市场经济基本特征" class="headerlink" title="2.市场经济基本特征"></a>2.市场经济基本特征</h3><ul>
<li>资源配置市场化</li>
<li>企业行为主体化</li>
<li>企业产权商品化</li>
<li>宏观调控间接化（政府通过市场作用企业）</li>
</ul>
<h3 id="3-市场经济基本规律"><a href="#3-市场经济基本规律" class="headerlink" title="3.市场经济基本规律"></a>3.市场经济基本规律</h3><ul>
<li>价值规律</li>
<li>供求规律</li>
<li>竞争规律</li>
</ul>
<h3 id="4-市场经济运行机制"><a href="#4-市场经济运行机制" class="headerlink" title="4.市场经济运行机制"></a>4.市场经济运行机制</h3><ul>
<li>价格机制（核心，信号灯）</li>
<li>供求机制</li>
<li>竞争机制（完全竞争/垄断、垄断竞争、寡头垄断）</li>
<li>风险机制（盈利、亏损、破产）</li>
<li>工资机制</li>
<li>利率机制</li>
</ul>
<h3 id="5-市场经济基本功能（5）"><a href="#5-市场经济基本功能（5）" class="headerlink" title="5.市场经济基本功能（5）"></a>5.市场经济基本功能（5）</h3><ul>
<li>资源优化配置</li>
<li>促进技术创新</li>
<li>信息传递 （纵横，计划经济only纵）</li>
<li>利益分配</li>
<li>外向开拓</li>
</ul>
<h3 id="6-社主市场经济"><a href="#6-社主市场经济" class="headerlink" title="6.社主市场经济"></a>6.社主市场经济</h3><p>是马思&amp;中国社主实践相结合的产物</p>
<h4 id="1）计划经济的局限"><a href="#1）计划经济的局限" class="headerlink" title="1）计划经济的局限"></a>1）计划经济的局限</h4><ul>
<li>特点</li>
<li>优点</li>
<li>不足（4）</li>
</ul>
<h4 id="2）社主市场经济理论的形成"><a href="#2）社主市场经济理论的形成" class="headerlink" title="2）社主市场经济理论的形成"></a>2）社主市场经济理论的形成</h4><p>1.世界</p>
<ul>
<li>列宁</li>
<li>斯大林（第一个，苏联模式）</li>
</ul>
<p>2.我国</p>
<ul>
<li>十二大</li>
<li>十二届三中全会（社主经济是有计划的商品经济）</li>
<li>十三大</li>
<li>邓小平南巡讲话</li>
<li>十四大（确立）</li>
</ul>
]]></content>
      <categories>
        <category>小小酥事业单位考试</category>
      </categories>
      <tags>
        <tag>小小酥</tag>
        <tag>每日总结</tag>
      </tags>
  </entry>
  <entry>
    <title>小小酥的每日学习小结（6）</title>
    <url>/2021/04/09/%E5%B0%8F%E5%B0%8F%E9%85%A5%E7%9A%84%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0%E5%B0%8F%E7%BB%93%EF%BC%886%EF%BC%89/</url>
    <content><![CDATA[<p>今天是小小酥备战事业单位考试的第六天。</p>
<span id="more"></span>
<h1 id="每日学习小结"><a href="#每日学习小结" class="headerlink" title="每日学习小结"></a>每日学习小结</h1><h2 id="一、社会主义市场经济"><a href="#一、社会主义市场经济" class="headerlink" title="一、社会主义市场经济"></a>一、社会主义市场经济</h2><p>1.公有制：国有、集体、混合所有制中国有、集体成分</p>
<p>2.多种所有制=非公有：个体、私营、外资（中外合资、中外合作、外商独资）</p>
<h3 id="1、建立“社主市场经济”体制的原因"><a href="#1、建立“社主市场经济”体制的原因" class="headerlink" title="1、建立“社主市场经济”体制的原因"></a>1、建立“社主市场经济”体制的原因</h3><p>市场经济的根本特征：促进生产的专业化、社会化—&gt;扩大&amp;加深社会分工</p>
<h3 id="2、“社主市场经济”基本特征（4）"><a href="#2、“社主市场经济”基本特征（4）" class="headerlink" title="2、“社主市场经济”基本特征（4）"></a>2、“社主市场经济”基本特征（4）</h3><p>和资本主义市场经济相比较</p>
<ul>
<li>所有制：公有制为主体，多种所有制共同发展</li>
<li>目的：满足日益增长的物质、美好需求</li>
<li>分配方式：按劳分配&amp;生产要素（效率&amp;公平）</li>
<li>宏观调控：国际、集体、个人根本利益一致</li>
</ul>
<h2 id="二、现代化企业"><a href="#二、现代化企业" class="headerlink" title="二、现代化企业"></a>二、现代化企业</h2><h3 id="1、企业的含义"><a href="#1、企业的含义" class="headerlink" title="1、企业的含义"></a>1、企业的含义</h3><p>盈利目的+社会经济组织</p>
<h3 id="2、企业的地位"><a href="#2、企业的地位" class="headerlink" title="2、企业的地位"></a>2、企业的地位</h3><p>最重要的市场主体</p>
<h3 id="3、市场主体的分类"><a href="#3、市场主体的分类" class="headerlink" title="3、市场主体的分类"></a>3、市场主体的分类</h3><ul>
<li>微观基础（5）</li>
<li>主要主体（3）</li>
<li>最主要主体（1）</li>
</ul>
<h3 id="4、企业成为市场主体的基本条件（3）"><a href="#4、企业成为市场主体的基本条件（3）" class="headerlink" title="4、企业成为市场主体的基本条件（3）"></a>4、企业成为市场主体的基本条件（3）</h3><ul>
<li>明确产权（有钱）</li>
<li>能自主经营</li>
<li>企业间地位平等</li>
</ul>
<h3 id="5、企业的分类"><a href="#5、企业的分类" class="headerlink" title="5、企业的分类"></a>5、企业的分类</h3><h4 id="1）所有权性质不同（3）"><a href="#1）所有权性质不同（3）" class="headerlink" title="1）所有权性质不同（3）"></a>1）所有权性质不同（3）</h4><ul>
<li>国有企业</li>
<li>集体企业</li>
<li>外资企业/三资企业</li>
</ul>
<h4 id="2）企业组织类型不同（3）"><a href="#2）企业组织类型不同（3）" class="headerlink" title="2）企业组织类型不同（3）"></a>2）企业组织类型不同（3）</h4><ul>
<li>业主制企业（1自然人）</li>
<li>合伙制企业（&gt;=2自然人）</li>
<li>公司制企业（法人：有限or股份）</li>
</ul>
<h4 id="3）我国法律规定-amp-确认的企业类型（8）"><a href="#3）我国法律规定-amp-确认的企业类型（8）" class="headerlink" title="3）我国法律规定&amp;确认的企业类型（8）"></a>3）我国法律规定&amp;确认的企业类型（8）</h4><p>8种企业<br>2种公司</p>
<ol>
<li>有限责任公司</li>
<li>国有独资公司（特殊的有限）</li>
<li>股份有限公司（可上市）</li>
<li>中外合资企业=股权式合资</li>
<li>外商独资企业</li>
</ol>
<p>上述有法人资格，有限责任</p>
<ol>
<li>个人独自企业</li>
<li>合伙企业</li>
<li>中外合作经营企业=契约式合作</li>
</ol>
<p>上述无法人资格，无限责任</p>
]]></content>
      <categories>
        <category>小小酥事业单位考试</category>
      </categories>
      <tags>
        <tag>小小酥</tag>
        <tag>每日总结</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习gym任务：Pendulum源码分析</title>
    <url>/2021/04/07/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0gym%E4%BB%BB%E5%8A%A1%EF%BC%9APendulum/</url>
    <content><![CDATA[<p>该任务是OpenAI Gym的environment之一，<a href="http://gym.openai.com/envs/Pendulum-v0/">官网关于该任务的链接</a></p>
<span id="more"></span>
<p>Pendulum的目标是将一个一端固定的直杆通过施加力矩使其可以荡到顶并保持直立。</p>
<img src="/2021/04/07/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0gym%E4%BB%BB%E5%8A%A1%EF%BC%9APendulum/1.png" class="">
<h2 id="Pendulum源代码的初始化"><a href="#Pendulum源代码的初始化" class="headerlink" title="Pendulum源代码的初始化"></a>Pendulum源代码的初始化</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, g=<span class="hljs-number">10.0</span></span>):</span><br>   self.max_speed = <span class="hljs-number">8</span>   <span class="hljs-comment"># 最大速度</span><br>   self.max_torque = <span class="hljs-number">2.</span>  <span class="hljs-comment"># 最大力矩</span><br>   self.dt = <span class="hljs-number">.05</span>  <span class="hljs-comment"># 微分时间，可以理解为执行一次step需要的时间，用来和角加速度乘法</span><br>   self.g = g     <span class="hljs-comment"># 重力加速度，默认为10.0</span><br>   self.m = <span class="hljs-number">1.</span>    <span class="hljs-comment"># 杆子质量（个人感觉这里也可以理解为密度），默认为1.0</span><br>   self.l = <span class="hljs-number">1.</span>    <span class="hljs-comment"># 杆子长度，默认为1.0</span><br>   self.viewer = <span class="hljs-literal">None</span><br><br>   high = np.array([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, self.max_speed], dtype=np.float32)<br>   self.action_space = spaces.Box(<br>     low=-self.max_torque,<br>     high=self.max_torque, shape=(<span class="hljs-number">1</span>,),<br>     dtype=np.float32<br>   )<br>   self.observation_space = spaces.Box(<br>     low=-high,<br>     high=high,<br>     dtype=np.float32<br>   )<br><br>   self.seed()<br></code></pre></td></tr></table></figure>
<p>这里的action_space代表力矩，-2～2的连续值</p>
<p>这里的observation_space是一个元组：(cos(theta), sin(theta), thetadot角速度)    theta代表偏转角度，这是由下面的方法得知的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reset</span>(<span class="hljs-params">self</span>):</span><br>  high = np.array([np.pi, <span class="hljs-number">1</span>])<br>  self.state = self.np_random.uniform(low=-high, high=high)<br>  self.last_u = <span class="hljs-literal">None</span><br>  <span class="hljs-keyword">return</span> self._get_obs()<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_get_obs</span>(<span class="hljs-params">self</span>):</span><br>  theta, thetadot = self.state<br>  <span class="hljs-keyword">return</span> np.array([np.cos(theta), np.sin(theta), thetadot])<br></code></pre></td></tr></table></figure>
<h2 id="Pendulum源代码的动作执行"><a href="#Pendulum源代码的动作执行" class="headerlink" title="Pendulum源代码的动作执行"></a>Pendulum源代码的动作执行</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">step</span>(<span class="hljs-params">self, u</span>):</span><br>  th, thdot = self.state  <span class="hljs-comment"># th := theta</span><br><br>  g = self.g<br>  m = self.m<br>  l = self.l<br>  dt = self.dt<br><br>  u = np.clip(u, -self.max_torque, self.max_torque)[<span class="hljs-number">0</span>]<br>  self.last_u = u  <span class="hljs-comment"># for rendering</span><br>  costs = angle_normalize(th) ** <span class="hljs-number">2</span> + <span class="hljs-number">.1</span> * thdot ** <span class="hljs-number">2</span> + <span class="hljs-number">.001</span> * (u ** <span class="hljs-number">2</span>)<br>  <span class="hljs-comment"># costs在末尾取相反数用作奖励，可见这个任务希望奖励数值越低越好</span><br>  newthdot = thdot + (-<span class="hljs-number">3</span> * g / (<span class="hljs-number">2</span> * l) * np.sin(th + np.pi) + <span class="hljs-number">3.</span> / (m * l ** <span class="hljs-number">2</span>) * u) * dt<br>  newth = th + newthdot * dt<br>  newthdot = np.clip(newthdot, -self.max_speed, self.max_speed)<br><br>  self.state = np.array([newth, newthdot])<br>  <span class="hljs-keyword">return</span> self._get_obs(), -costs, <span class="hljs-literal">False</span>, &#123;&#125;<br></code></pre></td></tr></table></figure>
<p>第17行定义了<strong>self.state</strong>：(theta, thetadot)    前者代表当前偏转角度，后者代表当前角速度</p>
<p>由13行可见，可以更改的参数是<strong>self.m</strong>和<strong>self.l</strong>，这两者修改哪个应该是都可以的，因为它们在<strong>step</strong>函数中仅出现一次，且是相乘，修改哪个都是一样的，可以理解为修改了杆子长度，这样可以使得该任务更泛化。</p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>要完成这个任务的关键在于这是一个连续动作任务，而非离散动作。使用DQN或其他方法都可以。</p>
]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
        <tag>gym</tag>
      </tags>
  </entry>
  <entry>
    <title>集群联邦学习：Clustered Federated Learning</title>
    <url>/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/</url>
    <content><![CDATA[<p>今日调研了Felix Sattler等人提出的集群联邦学习，<a href="https://ieeexplore.ieee.org/abstract/document/9174890">论文链接</a>。</p>
<span id="more"></span>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>联邦学习中假设全局模型可以同时拟合所有参与方的本地数据，但是显然是不可能的，下图中给出反例。</p>
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/1.jpg" class="">
<p><strong>假设1</strong>：存在$\theta^*$在所有参与方的数据分布上都可以最小化损失：</p>
<p>$R_i(\theta^*)\leq {\underset {\theta}{min}}R_i(\theta)$         $i=1,…,M$</p>
<p>这样，如果所有参与方满足假设1，就称所有参与方的本地数据分布是<strong><font color="#ff0000">全等</font></strong>的。但是事实上，假设1在联邦学习中经常被违反，例如下面这四个场景：</p>
<ul>
<li>不同的参与方具有不同的喜好：例如要在很多个用户所拥有的人脸数据集上联邦训练一个“人脸吸引力”分类器，但是不同的用户对人脸的喜好是不一样的，这导致很难满足假设1。</li>
<li>模型复杂度受限制：假设许多用户正视图联邦训练一个语言模型，用于私有文本的下一个单词预测。在这个场景中，客户的文本信息的统计数据会根据人口统计因素、兴趣等发生很大的变化，一个不够复杂的模型不能同时拟合所有客户端的数据。</li>
<li>敌手的存在：如果用户中存在敌手，敌手可以故意改变自己的本地数据分布，对联邦模型造成恶劣的影响。</li>
<li>联邦多任务学习：联邦多任务学习的目标是为每个参与方提供一个最适合其本地数据分布的模型。普通的联邦学习框架下，只有一个单一的全局模型无法实现这一目标。</li>
</ul>
<p>那么，推广一下传统的联邦学习假设呢？</p>
<p><strong>假设2（CFL）</strong>：存在一个对参与方的分割$C=\{c1,…,c_K\},\cup _{k=1}^Kc_k=\{1,…,M\} $，在每一个分割$c \in C$内满足常规的联邦学习假设，即假设1。</p>
<h2 id="集群联邦学习"><a href="#集群联邦学习" class="headerlink" title="集群联邦学习"></a>集群联邦学习</h2><p>首先作者给出了该论文中涉及的重要数学符号的介绍，如下图。</p>
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/2.jpg" class="">
<p>最重要的任务就是解决如何划分参与方。</p>
<h3 id="基于余弦相似度的二分法"><a href="#基于余弦相似度的二分法" class="headerlink" title="基于余弦相似度的二分法"></a>基于余弦相似度的二分法</h3><p><strong>定义1</strong>：当$M\ge K \ge 2$时，令$I:\{1,…,M\}\rightarrow\{1,…,K\}$为一个映射，将参与方$i$映射为数据分布的编号$I(i)$，对应的数据分布为$\phi_{I(i)}$，当且仅当下式成立时，称二分$c_1\cup c_2=\{1,…,M\}$是正确的（$c_1,c_2$均为非空集合）：</p>
<script type="math/tex; mode=display">I(i)\neq I(j) \qquad \forall i\in c_1,j\in c_2</script><p>简单来说，也就是当数据分布相同的参与方被分在了同一组时，划分就是正确的。</p>
<p>有了这个映射之后，就可以确定所有参与方本地数据的数据分布$D_i\sim\phi_{I(i)}(x,y)$，也可以确定每个参与方上的经验风险$r_i(\theta)=\sum_{(x,y)\in D_i}l_\theta (f(x),y)$，并且当参与方本地的数据集足够大时，有$r_i(\theta)\approx R_{I(i)}(\theta)$</p>
<p>假设有数据分布一共有两个，那么联邦学习的目标函数可以写作：</p>
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/3.png" class="">
<p>那么在最优解处，有<script type="math/tex">0=\nabla F(\theta^*)=a_1\nabla R_1(\theta^*)+a_2\nabla R_2(\theta^*)</script>，如果两个数据分布不全等，就会有<script type="math/tex">\nabla R_1(\theta^*)=-\frac{a_2}{a_1}\nabla R_2(\theta^*)\neq 0</script>，这说明<script type="math/tex">\nabla R_1(\theta^*)</script>和<script type="math/tex">\nabla R_2(\theta^*)</script>对应位置的元素异号（下图中的计算公式个人感觉将两个R都看作标量，那么计算余弦相似度时为什么一个是1一个是-1就好理解了）。故而，任意两个参与方的梯度更新的余弦相似度计算如下：</p>
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/4.png" class="">
<p>可以理解为在一个正确的划分下，随着联邦学习的推进，同一集群内部的梯度向量之间的余弦相似度会始终较小，但不同集群的梯度向量之间的余弦相似度会越来越多，如下图所示。</p>
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/9.png" class="">
<p>随后就可以求取来自两个不同集群的参与方的梯度更新的最大余弦相似度，应让其最小化，并且有一个边界（边界推导过程没有看懂，回头再仔细看看原文吧……）：</p>
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/5.png" class="">
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/6.png" class="">
<p>这个很好理解，因为在一个合理的划分下，来自两个不同集群的样本之间余弦相似度应该很小，让两个集群中相似度最大的样本之间的相似度最小化，就得到了一个好的划分。同时还要求取来自同一个集群的任意两个样本的最小余弦相似度，这个最小余弦相似度也有边界（同样，推导过程回头再仔细看看原文，现在还没看懂……）：</p>
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/7.png" class="">
<p><strong>引理1</strong>：当$\alpha ^{min}_{intra}&gt;\alpha^{max}_{cross}$时，下式中的划分就是一个<strong>定义1</strong>中正确的划分：</p>
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/8.png" class="">
<p><strong>定义2</strong>：$g(\alpha):=\alpha _{intra}^{min}-\alpha^{max}_{cross}$，将其称之为组间差异，$g(\alpha)&gt;0$时，<strong>引理1</strong>中的划分就是对的。</p>
<h3 id="算法与解法"><a href="#算法与解法" class="headerlink" title="算法与解法"></a>算法与解法</h3><p>CFL算法首先将所有参与方看作同属一个集群$c=\{1,…,M\}$，进行联邦学习后得到的平稳解<script type="math/tex">\theta^*</script>（即使得联邦损失函数梯度绝对值小于<script type="math/tex">\epsilon_1</script>的解）如果满足$0\leq{\underset {i\in c}{max}}||\nabla_\theta r_i(\theta^*)||\leq \epsilon_2$，也就是在集群内的所有参与方上都将损失函数值降在了$\epsilon_2$以下，则CFL算法结束，得到目标模型；若无法满足，则说明需要进行集群切分。</p>
<h4 id="集群切分（二分）"><a href="#集群切分（二分）" class="headerlink" title="集群切分（二分）"></a>集群切分（二分）</h4><img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/10.png" class="">
<p>上图中的第3行，是将余弦相似度矩阵按值大小将索引排序（从大到小，有的博客说是从小到大，但我认为$argsort(-\alpha)$代表$\alpha$值从大到小），这里的索引是将二维矩阵压平，变成一维矩阵得到的索引。举个例子，如果$M=10$，那么（1，3）就转化为1*10+3=13。所以第6行中的$i_1$和$i_2$分别代表二维矩阵中的索引，即该值对应哪两个参与方之间的余弦相似度。这里就是每次把余弦相似度最大的两个参与方的分组合并，每一次有效合并都可以使$|C|$的大小降低，直至降低为2时终止，这样$C$中就有划分（二分）后的结果了。</p>
<h4 id="CFL算法"><a href="#CFL算法" class="headerlink" title="CFL算法"></a>CFL算法</h4><p>当切分后，如果不满足${\underset {i\in c}{max}}||\nabla_\theta r_i(\theta^*)||\leq \epsilon_2$，同时又满足$\alpha ^{min}_{intra}&gt;\alpha^{max}_{cross}$，那么就要继续切分。后者好计算，而前者较难计算，因此前者只能依据其定义式，进行估计如下：</p>
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/11.png" class="">
<p>因此，当$\gamma_{max}&lt;\sqrt{\frac{1-\alpha_{cross}^{max}}{2}}$时，划分就是正确的，并且可以继续划分。</p>
<p>所以CFL算法如下，这是一个递归过程，如果可以划分就继续划分，无须划分则返回目标模型：</p>
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/12.png" class="">
<p>该过程如下图所示：</p>
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/13.png" class="">
<h4 id="动态加入参与方"><a href="#动态加入参与方" class="headerlink" title="动态加入参与方"></a>动态加入参与方</h4><p>如果有参与方在训练中途加入，也是可以的。因为在每次进行划分时，CFL都会进行缓存划分两端的信息（如下图）：</p>
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/14.png" class="">
<p>中途加入的参与方只需按照下图算法就可以迅速找到自己所属的节点，并一同进行联邦学习：</p>
<img src="/2021/03/25/%E9%9B%86%E7%BE%A4%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%9AClustered-Federated-Learning/15.png" class=""> 
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇论文提出的CFL算法中虽然一些数学证明晦涩难懂，但是大体思路非常新颖，值得学习。</p>
]]></content>
      <categories>
        <category>联邦学习</category>
      </categories>
      <tags>
        <tag>联邦学习</tag>
      </tags>
  </entry>
</search>
